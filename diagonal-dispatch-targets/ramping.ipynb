{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57562118-ffa8-48bb-a7d8-4d66a4f84bba",
   "metadata": {},
   "source": [
    "# Linear Ramping Difference Check\n",
    "\n",
    "By Matthew Davis\n",
    "\n",
    "This code performs the simulations for my masters thesis. This is for the section related to diagonal dispatch targets.\n",
    "\n",
    "Here we download electricity price data for several regions. Then we run a linear optimiser to find the optimal charge/discharge production schedule for a hypothetical battery. We do this twice for each series of prices:\n",
    "\n",
    "* *stepped*: within each time interval, the power input/output is constant. At the boundary between trading periods, the power level changes instantaneously.\n",
    "* *diagonal*: Power level is always continuous. It is a sequence of diagonal 'dot-to-dot ramps'\n",
    "\n",
    "The most important part of this code is the function `dispatch_mode` in section `Dispatch Mode`. That's the point of the whole paper.\n",
    "\n",
    "This notebook can be run on any normal laptop. The computational requirements are not large, in terms of memory. However it takes several hours to run. (Set `debug=True` later to speed it up while modifying the notebook.) This includes downloading the data, which will be skipped automatically on subsequent runs.\n",
    "\n",
    "Install dependencies with `pip install -r requirements.txt`. Then modify `data_location` to point somewhere appropriate for your device.\n",
    "\n",
    "For dataframes, I use [Polars](https://docs.pola.rs/) instead of Pandas, just because I think the interface is nicer, and that's what I'm used to these days. If you're not familiar with Polars, but you know Pandas, you'll still be able to read and understand most of the Polars code.\n",
    "\n",
    "The code runs simulations for Europe, but I don't include the results in my thesis. It turns out Europe's grid rules are quite complicated, and this diagonal/linear dispatch constraint does not apply. But I'm leaving the code in because it might be handy to have later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01c0968-a28a-4153-8096-c4f9a6081921",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ce9486ac-1f0b-4f44-b26c-0b11bba3e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import urllib.request\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from random import randrange\n",
    "from time import time\n",
    "from zipfile import ZipFile\n",
    "from itertools import product\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "\n",
    "\n",
    "from requests import Session\n",
    "from requests.adapters import HTTPAdapter\n",
    "from tqdm import tqdm\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "import polars as pl\n",
    "from nemosis import dynamic_data_compiler\n",
    "from pyomo.environ import (\n",
    "    AbstractModel,\n",
    "    Binary,\n",
    "    Boolean,\n",
    "    ConcreteModel,\n",
    "    Constraint,\n",
    "    NonNegativeReals,\n",
    "    Objective,\n",
    "    Param,\n",
    "    Reals,\n",
    "    Set,\n",
    "    SolverFactory,\n",
    "    Var,\n",
    "    maximize,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c25f27cd-0e35-4fed-b238-aacb02972e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where to store the raw price data\n",
    "# About 10GB\n",
    "data_location = \"/home/matthew/Data/ramping/\"\n",
    "\n",
    "# where to store the tables and graphs for the paper\n",
    "results_location = \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8ec97b39-b466-4123-ba4b-a9167ab77f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "aus_data_location = \"/home/matthew/Data/nemosis/\"\n",
    "eu_data_location = os.path.join(data_location, \"Europe\")\n",
    "miso_location = os.path.join(data_location, \"USA\", \"MISO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "202172ed-b406-43eb-97e5-d559f54b9cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = dt.date(2024, 1, 1)\n",
    "end_date = dt.date(2024, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4fbe9e21-2f9f-4fb5-bdb6-edcbbb827912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic unit conversions\n",
    "ms_per_s = 1000\n",
    "s_per_min = 60\n",
    "min_per_h = 60\n",
    "ms_per_h = ms_per_s * s_per_min * min_per_h\n",
    "\n",
    "gw_per_mw = 1 / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4580d-3d9f-4ee7-8833-390c3148818c",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "36ba7887-b534-47a7-9706-6a9ce0327982",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [data_location, aus_data_location, eu_data_location, miso_location, results_location]:\n",
    "    os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fece65-3342-40b4-b4b7-855f445ae29f",
   "metadata": {},
   "source": [
    "### Australia\n",
    "\n",
    "We use [nemosis](https://github.com/UNSW-CEEM/NEMOSIS/) to download the [`DISPATCHPRICE` MMS table](https://nemweb.com.au/Reports/Current/MMSDataModelReport/Electricity/Electricity%20Data%20Model%20Report_files/Electricity%20Data%20Model%20Report_toc.htm) from AEMO's [nemweb](https://www.nemweb.com.au/Data_Archive/Wholesale_Electricity/MMSDM/2025/MMSDM_2025_03/MMSDM_Historical_Data_SQLLoader/DATA/). \n",
    "\n",
    "Note that:\n",
    "\n",
    "* We delete `INTERVENTION == 1` columns. Those are academic counterfactuals when AEMO manually overrides instructions for specific generators. `INTERVENTION == 0` is what generators get paid, so they're the 'real' prices we're concerned about.\n",
    "* Timestamps in AEMO data always refer to the *end* of the interval, not the start. This doesn't really matter for our purposes.\n",
    "* `RRP` means price ($/MWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dbcf0df6-bb4f-4bc9-9ace-507e684c23e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prices in Australia are 5-minute granularity\n",
    "interval_min_aus = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3623ebf-34cc-48fe-ad35-52572fb88ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Compiling data for table DISPATCHPRICE\n"
     ]
    }
   ],
   "source": [
    "nemosis_dt_fmt = \"%Y/%m/%d %H:%M:%S\"\n",
    "\n",
    "aus_df_pd = dynamic_data_compiler(\n",
    "    start_date.strftime(nemosis_dt_fmt),\n",
    "    end_date.strftime(nemosis_dt_fmt),\n",
    "    \"DISPATCHPRICE\",\n",
    "    aus_data_location,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c55eee-971c-4355-81c9-22d87d97db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aus_df = (\n",
    "    pl.from_pandas(aus_df_pd)\n",
    "    .filter(pl.col(\"INTERVENTION\") == 0)\n",
    "    .select(time=\"SETTLEMENTDATE\", region=\"REGIONID\", price=\"RRP\")\n",
    ")\n",
    "\n",
    "aus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f86cc0-43b2-48d0-bbee-de622dc75109",
   "metadata": {},
   "source": [
    "### Europe\n",
    "\n",
    "We download European price data from [Ember](https://ember-energy.org/data/european-wholesale-electricity-price-data/). Note that this is day ahead data, not intra-day, because intraday prices are not public. (You have to pay a lot.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136e420-5379-469f-8c3e-da4ada575596",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://storage.googleapis.com/emb-prod-bkt-publicdata/public-downloads/price/outputs/european_wholesale_electricity_price_data_hourly.zip\"\n",
    "zip_path = os.path.join(eu_data_location, \"raw.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06427ede-5b7a-47e0-8733-c99f1ce82678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't re-download if already present\n",
    "if not os.path.exists(zip_path):\n",
    "    urllib.request.urlretrieve(url, zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c70bfc8-485b-447c-9236-53e831275c0b",
   "metadata": {},
   "source": [
    "Now read in the CSV.\n",
    "\n",
    "Inside the zip, it looks like:\n",
    "\n",
    "```\n",
    "Country,ISO3 Code,Datetime (UTC),Datetime (Local),Price (EUR/MWhe)\n",
    "France,FRA,2015-01-01 00:00:00,2015-01-01 01:00:00,36.56\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1098d-8ae1-4e3a-9e38-19a600949586",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(zip_path, \"r\") as zf:\n",
    "    with zf.open(\"all_countries.csv\", \"r\") as csv_f:\n",
    "        eu_df = pl.read_csv(csv_f, try_parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be1e50-4d25-467f-b23d-e5fbfaaf6f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_df = eu_df.select(\n",
    "    region=\"Country\",\n",
    "    time=\"Datetime (UTC)\",\n",
    "    price=\"Price (EUR/MWhe)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe1bfa-1f58-4ca5-9d32-3f2c096244c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which countries do we have data for?\n",
    "(\n",
    "    eu_df\n",
    "    .select(\"region\")\n",
    "    .unique()\n",
    "    .sort(\"region\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c8282-6eac-43cf-a0fd-5f641d05fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this data is hourly\n",
    "interval_min_eu = min_per_h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d178287-23ac-4543-93c3-2172585dbb17",
   "metadata": {},
   "source": [
    "### MISO\n",
    "\n",
    "Download from [here](https://www.misoenergy.org/markets-and-operations/real-time--market-data/market-reports/#nt=%2FMarketReportType%3AHistorical%20LMP%2FMarketReportName%3AReal-Time%205-Min%20ExAnte%20LMPs%20(xlsx)&t=10&p=0&s=MarketReportPublished&sd=desc).\n",
    "\n",
    "Market Reports > Historical LMP > Real-Time 5-Min ExAnte LMPs (xlsx).\n",
    "One file for each day.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c86829c-087f-4069-81e8-634bf88e5fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "s = Session()\n",
    "\n",
    "# aggressive retries. MISO's server is very slow\n",
    "retry = Retry(\n",
    "    total=8,\n",
    "    read=8,\n",
    "    connect=8,\n",
    "    backoff_factor=1.5,\n",
    "    raise_on_status=False\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "s.mount(\"http://\", adapter)\n",
    "s.mount(\"https://\", adapter)\n",
    "\n",
    "\n",
    "d = start_date\n",
    "dates = [start_date]\n",
    "while d <= end_date:\n",
    "    dates.append(d)\n",
    "    d += dt.timedelta(days=1)\n",
    "\n",
    "for d in tqdm(dates):\n",
    "    url = f\"https://docs.misoenergy.org/marketreports/{d.strftime('%Y%m%d')}_5min_exante_lmp.xlsx\"\n",
    "    local_xls_path = os.path.join(miso_location, url.split(\"/\")[-1])\n",
    "    local_pq_path = os.path.join(miso_location, url.split(\"/\")[-1].rpartition('.')[0] + \".parquet\")\n",
    "\n",
    "    # download\n",
    "    if not os.path.exists(local_xls_path):  # don't re-download\n",
    "        \n",
    "        try:\n",
    "            with s.get(url, stream=True) as r:\n",
    "                r.raise_for_status()\n",
    "                with open(local_xls_path, \"wb\") as f:\n",
    "                    for chunk in r.iter_content(chunk_size=8192):\n",
    "                        if chunk:  # filter out keep-alive chunks\n",
    "                            f.write(chunk)\n",
    "        except Exception:\n",
    "            if os.path.exists(local_xls_path):\n",
    "                os.remove(local_xls_path)\n",
    "            raise\n",
    "\n",
    "    # convert to parquet\n",
    "    if not os.path.exists(local_pq_path):\n",
    "        (\n",
    "            pl.read_excel(\n",
    "                local_xls_path, \n",
    "                read_options = {\"header_row\": 3}, \n",
    "            )\n",
    "            .lazy()\n",
    "            .cast({\"RT Ex-Ante LMP\": pl.Float64}) # in case some are empty\n",
    "            .group_by(pl.col(\"Time (EST)\").alias(\"time\"))\n",
    "            .agg(\n",
    "                pl.col(\"RT Ex-Ante LMP\").mean().alias(\"price\")\n",
    "            )\n",
    "            .sink_parquet(local_pq_path)\n",
    "        )\n",
    "\n",
    "    if pl.read_parquet_schema(local_pq_path)['price'] == pl.String():\n",
    "        print(f\"{local_pq_path.split('/')[-1]}: {pl.read_parquet_schema(local_pq_path)}\")\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e93696e-a993-4919-b839-215b3afbb3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from disk\n",
    "miso_df = pl.read_parquet(f\"{miso_location}/*.parquet\")\n",
    "miso_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e1af7-ffc2-456e-b5ae-70dbc42f7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is 5 minute data\n",
    "interval_min_miso = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49498929-6cec-433a-8e66-6152268d5ca1",
   "metadata": {},
   "source": [
    "### Sample\n",
    "\n",
    "Construct some trivial data to test the code gives reasonable optimal strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5405d525-ea74-44bb-a661-c1ff7de63864",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_datetime = dt.datetime(start_date.year, start_date.month, start_date.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951f1b6-e7d5-48e1-8c24-c1c7bd28d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = [10, 100, 10, 10, 100, 100, 10, 10, 10, 100] + [\n",
    "    randrange(0, 100) for _ in range(20)\n",
    "]\n",
    "sample_prices = pl.DataFrame(\n",
    "    {\n",
    "        \"price\": prices,\n",
    "        \"time\": pl.datetime_range(\n",
    "            start=start_datetime,\n",
    "            end=start_datetime + dt.timedelta(hours=len(prices) - 1),\n",
    "            interval=\"1h\",\n",
    "            eager=True,\n",
    "        ),\n",
    "    }\n",
    ").with_columns(region=pl.lit(\"fake\"))\n",
    "\n",
    "\n",
    "sample_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a54b4-0948-4e9d-9a8e-74a7fb726f55",
   "metadata": {},
   "source": [
    "## Combine and Prepare Price Data\n",
    "\n",
    "We want one Polars dataframe, with columns:\n",
    "\n",
    "* `region`, e.g. \"France\" or \"NSW1\" (part of Aus)\n",
    "* `price`\n",
    "* `period` (integer starting at 0 for each region)\n",
    "* `time` (datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0a0c8d-d467-4d3d-ac14-fb5ea9efc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = (\n",
    "    pl.concat(\n",
    "        [\n",
    "            sample_prices,\n",
    "            aus_df,\n",
    "            eu_df,\n",
    "            miso_df.with_columns(pl.lit('MISO').alias('region')),\n",
    "        ],\n",
    "        how=\"diagonal_relaxed\",\n",
    "    )\n",
    "    .filter(pl.col(\"time\").is_between(start_date, end_date))\n",
    "    .filter(pl.col(\"price\").is_not_null())\n",
    "    .sort(\"region\", \"time\")\n",
    "    .group_by(\"region\")\n",
    "    .map_groups(lambda group: group.with_row_index(\"period\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8194d59-48b3-44fd-87ad-69d8abdcb9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict to only these regions\n",
    "# otherwise it takes too long\n",
    "regions = [\"SA1\", \"QLD1\", \"NSW1\", \"VIC1\", \"TAS1\", \"MISO\"]\n",
    "#regions = [\"fake\"]\n",
    "\n",
    "price_df = price_df.filter(pl.col(\"region\").is_in(regions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffeb2d5-5c75-4785-ab99-45f46df2ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_metadata_df = (\n",
    "    price_df.select(\"region\")\n",
    "    .unique()\n",
    "    .with_columns(\n",
    "        pl.when(pl.col(\"region\").is_in(aus_df[\"region\"].implode()))\n",
    "        .then(interval_min_aus)\n",
    "        .when(pl.col(\"region\") == \"MISO\")\n",
    "        .then(interval_min_miso)\n",
    "        .otherwise(interval_min_eu)\n",
    "        .alias(\"interval_min\")\n",
    "    )\n",
    "    .with_columns((pl.col(\"interval_min\") / min_per_h).alias(\"h_per_interval\"))\n",
    ")\n",
    "# convert to dict for easy lookup later\n",
    "region_metadata = {\n",
    "    r: {\"h_per_interval\": h, \"interval_min\": i}\n",
    "    for (r, i, h) in zip(\n",
    "        region_metadata_df.to_dict(as_series=False)[\"region\"],\n",
    "        region_metadata_df.to_dict(as_series=False)[\"interval_min\"],\n",
    "        region_metadata_df.to_dict(as_series=False)[\"h_per_interval\"],\n",
    "    )\n",
    "}\n",
    "region_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a08ca6-2ce6-4f44-bcd4-8309338f9f7c",
   "metadata": {},
   "source": [
    "## Optimising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46af48d-3883-40c7-a388-586ab4498812",
   "metadata": {},
   "source": [
    "### Simple Simulation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ca12ed-a022-4d3d-acc7-2cafcaf8ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how big is the battery?\n",
    "battery_max_power = 1  # MW\n",
    "battery_depth_h = 2  # hours\n",
    "battery_depth_mwh = battery_max_power * battery_depth_h\n",
    "\n",
    "# starting conditions, chosen arbitrarily\n",
    "initial_charge = battery_depth_mwh / 2\n",
    "initial_power = battery_max_power / 2\n",
    "\n",
    "round_trip_efficiency = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f28eb6e-66ee-44b5-b15c-5608a7075a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AbstractModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c151dd8-e701-43ce-9788-759d5c11be93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.period = Set(ordered=True, name=\"period\")\n",
    "model.prices = Param(model.period, domain=Reals, name=\"price\")\n",
    "model.h_per_interval = Param(domain=Reals, name=\"h_per_interval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99538ad-c7d3-4cbc-a3b2-bbae71173ec8",
   "metadata": {},
   "source": [
    "### Variables and Constraints\n",
    "\n",
    "*Parameters* are things we know at the start of the computation. e.g. prices. (We assume perfect forsight of prices). \n",
    "*Variables* are things we decide (i.e. how much power to produce).\n",
    "\n",
    "In practice generators/batteries choose bids, which are a set of power levels conditional on price. We're abstracting from that and pretending firms choose production levels (i.e. power) directly, because we're assuming perfect forsight of prices.\n",
    "\n",
    "*Power* is the instantaneous *flow* of the good (MW, megawatts). *Energy* is a stock (MWh, megawatt hours), which accumulates as the *charge* on the battery.\n",
    "\n",
    "To account for round-trip losses, we have a separate charge and discharge variable. Then we have constraints to limit them so we don't charge and discharge at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0873595e-a851-46d1-9126-85258ef62938",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.directions = Set(\n",
    "    initialize=[\"charge\", \"discharge\"], ordered=True, name=\"direction\"\n",
    ")\n",
    "\n",
    "# MW power\n",
    "# at the end of each interval\n",
    "# separated by charge/discharge (gross, not net)\n",
    "model.power_gross_end = Var(\n",
    "    model.period,\n",
    "    model.directions,\n",
    "    domain=NonNegativeReals,\n",
    "    bounds=[0, battery_max_power],\n",
    "    name=\"power_gross_end\",\n",
    ")\n",
    "\n",
    "# MW power\n",
    "# at the end of each interval\n",
    "# netted (sum of charge/discharge together)\n",
    "# positive means supplied to grid (discharge)\n",
    "model.power_net_end = Var(\n",
    "    model.period,\n",
    "    domain=Reals,\n",
    "    bounds=[-battery_max_power, battery_max_power],\n",
    "    name=\"power_net_end\",\n",
    ")\n",
    "\n",
    "# MW power\n",
    "# averaged across the interval\n",
    "# separated by charge/discharge (gross)\n",
    "model.power_gross_avg = Var(\n",
    "    model.period,\n",
    "    model.directions,\n",
    "    domain=NonNegativeReals,\n",
    "    bounds=[0, battery_max_power],\n",
    "    name=\"power_gross_avg\",\n",
    ")\n",
    "\n",
    "# MW supplied/consumed from grid\n",
    "# averaged over whole period\n",
    "# charge + discharge combined (net)\n",
    "# positive means supplied\n",
    "model.power_net_avg = Var(\n",
    "    model.period,\n",
    "    domain=Reals,\n",
    "    bounds=[-battery_max_power, battery_max_power],\n",
    "    name=\"power_net_avg\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc9fdd-4424-4a09-80ee-f7ae546b5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net power is the sum of charge and discharge power\n",
    "# arbitrarily define positive power as being discharging, negative as charge\n",
    "# so positive power means positive revenue (when prices are positive)\n",
    "def power_netting_end(model, p):\n",
    "    return (\n",
    "        model.power_net_end[p]\n",
    "        == model.power_gross_end[p, \"discharge\"]\n",
    "        - model.power_gross_end[p, \"charge\"]\n",
    "    )\n",
    "\n",
    "\n",
    "model.power_netting_end_constraint = Constraint(\n",
    "    model.period, rule=power_netting_end\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d1342-ea48-4767-8f6d-c7021f335da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# netting of averages\n",
    "def power_netting_avg(model, p):\n",
    "    return (\n",
    "        model.power_net_avg[p]\n",
    "        == model.power_gross_avg[p, \"discharge\"] - model.power_gross_avg[p, \"charge\"]\n",
    "    )\n",
    "\n",
    "# redundant constraint, so omit it\n",
    "#model.power_netting_avg_constraint = Constraint(model.period, rule=power_netting_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a55b46a-4f50-44e1-b4e1-ff99e0ef25bb",
   "metadata": {},
   "source": [
    "Given the <100% efficiency, the optimal solution during negative prices is to simultaneously charge and discharge, to get paid to waste power. However this is not physically possible.\n",
    "\n",
    "Although if last period we were charging, and this period we want to discharge, due to the linear ramping, we will have to continue charging for the first few seconds/minutes, charging more slowly, then eventually flip to discharging. So within one interval we do both.\n",
    "\n",
    "So instead I'll use a lazy solution, to just cap the sum of the two at the maximum of each individual charge/discharge. This is equivilent to saying that the battery can charge for x% of an interval, and discharge for the remainder of the interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82afd1b-fd7f-4568-be5b-88bda61e20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_one_direction(model, p):\n",
    "    return (\n",
    "        model.power_gross_end[p, \"charge\"]\n",
    "        + model.power_gross_end[p, \"discharge\"]\n",
    "        <= battery_max_power\n",
    "    )\n",
    "\n",
    "model.only_one_direction_constr = Constraint(\n",
    "    model.period, rule=only_one_direction\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c9d7eb-9ef4-4799-8547-267b600ff5a8",
   "metadata": {},
   "source": [
    "### Dispatch Mode\n",
    "\n",
    "This is what the difference is between the two approaches. This is the most important part of this notebook. The rest of the optimiser stuff is a straightforward battery optimisation.\n",
    "\n",
    "Here we say `step` approach is when the starting power each interval can be different to the end of the previous interval, and power is constant within each interval. Whereas `diagonal` means it must start at the same level it finished the previous period at, and then we will ramp the power level (smoothly change production level) towards the power level at the end of the interval.\n",
    "\n",
    "```\n",
    "        ----|\n",
    "----|   |   |\n",
    "    |   |   |\n",
    "    ----|   ----\n",
    "```\n",
    "\n",
    "vs\n",
    "\n",
    "```\n",
    "-----      /\\\n",
    "     \\    /  \\\n",
    "      \\  /    \\\n",
    "       \\/      \\\n",
    "```\n",
    "\n",
    "We have variables for power at the _end_ of each interval. For the stepped approach, the average power during an interval equals the power at the end. For the diagonal approach, the average power during an interval is the average of the power at the end of this interval and the end of the previous interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26769ecf-7359-4fcd-aed4-5ed9232fc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.is_diagonal = Param(domain=Boolean)\n",
    "\n",
    "def dispatch_mode(model, p):\n",
    "    if model.is_diagonal:\n",
    "        if p > 0:\n",
    "            start_power = model.power_net_end[p - 1]\n",
    "        else:\n",
    "            # initial constraint\n",
    "            start_power = initial_power\n",
    "        end_power = model.power_net_end[p]\n",
    "        return model.power_net_avg[p] == (start_power + end_power) / 2\n",
    "    else:\n",
    "        # constant power\n",
    "        return model.power_net_avg[p] == model.power_net_end[p]\n",
    "\n",
    "\n",
    "model.dispatch_mode_constr = Constraint(model.period, rule=dispatch_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d199dde-c684-4a30-be65-c51e03ec168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same again, but separate charge/discharge\n",
    "# this may be a redundant constraint\n",
    "\n",
    "def dispatch_mode_gross(model, p, d):\n",
    "    if model.is_diagonal:\n",
    "        if p > 0:\n",
    "            start_power = model.power_gross_end[p - 1, d]\n",
    "        else:\n",
    "            # initial constraint\n",
    "            start_power = initial_power\n",
    "        end_power = model.power_gross_end[p, d]\n",
    "        return model.power_gross_avg[p, d] == (start_power + end_power) / 2\n",
    "    else:\n",
    "        # constant power\n",
    "        return model.power_gross_avg[p, d] == model.power_gross_end[p, d]\n",
    "\n",
    "\n",
    "model.dispatch_mode_constr_gross = Constraint(model.period, model.directions, rule=dispatch_mode_gross)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31f918-e84a-49f4-b456-88921b283ae4",
   "metadata": {},
   "source": [
    "### Charge Level\n",
    "\n",
    "Charge level is in MWh, energy. It's a stock, not flow.\n",
    "This stops us from discharging fully, repeatedly, every interval (which would maximize revenue, but is impossible)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f16c67-c21e-4915-8505-ce65dd48d8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MWh at end of the interval\n",
    "model.charge_end = Var(\n",
    "    model.period,\n",
    "    domain=NonNegativeReals,\n",
    "    bounds=[0, battery_depth_mwh],\n",
    "    name=\"charge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd471328-330e-4ee8-bc87-4c7464975837",
   "metadata": {},
   "source": [
    "For linking power (flow) to charge (stock), we apply a round trip energy loss `round_trip_efficiency`. This asymmetry is why we separate charge and discharge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7963917-8ce3-4493-80da-a2d5e8ff2d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charge_from_power(model, p):\n",
    "    # * h_per_interval to go from MW to MWh\n",
    "    if p > 1:\n",
    "        start_charge = model.charge_end[p-1]\n",
    "    else:\n",
    "        start_charge = initial_charge\n",
    "\n",
    "    charge_change = model.h_per_interval * (\n",
    "        model.power_gross_avg[p, \"charge\"]\n",
    "        * round_trip_efficiency\n",
    "        - model.power_gross_avg[p, \"discharge\"]\n",
    "    )\n",
    "    return model.charge_end[p] == start_charge + charge_change\n",
    "\n",
    "model.charge_from_power_constraint = Constraint(model.period, rule=charge_from_power)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b88065-fcb1-4d68-9075-0da87f60e13c",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "The objective is to maximize spot market revenue,\n",
    "(given a sunk infrastructure investment).\n",
    "The only cost is the cost of charging the battery. So this is a pure temporal arbitrage business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5619b6f-eecd-450e-9823-d86e2afdd62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.revenue = Var(model.period, domain=Reals, name=\"revenue\")\n",
    "\n",
    "\n",
    "# definition of revenue each period\n",
    "def revenue_eq(model, p):\n",
    "    # note that power is MW, price is $/MWh\n",
    "    # so we need to scale by number of hours\n",
    "    return (\n",
    "        model.revenue[p]\n",
    "        == model.power_net_avg[p] * model.prices[p] * model.h_per_interval\n",
    "    )\n",
    "\n",
    "\n",
    "model.revenue_def = Constraint(model.period, rule=revenue_eq)\n",
    "\n",
    "\n",
    "# summing up revenue\n",
    "# In a callable function, because we don't yet know how many time periods we will have.\n",
    "def total_revenue_rule(model):\n",
    "    return sum(model.revenue[p] for p in model.period)\n",
    "\n",
    "\n",
    "model.revenue_total = Objective(\n",
    "    expr=total_revenue_rule,\n",
    "    sense=maximize,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da33ab2-2216-4172-94f3-2d11fc6540ec",
   "metadata": {},
   "source": [
    "### Solve\n",
    "\n",
    "Run the solver now. This is what takes a long time.\n",
    "\n",
    "The solver is single-threaded. I'm lazy, and not wrapping it in `multiprocessing.Pool`. Partly because if someone else wants to run this, but they use windows, they may have troubles. (multiprocessing + Jupyter + Windows don't work together). Also, to keep the memory footprint small enough for a normal lapop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77efda6e-df7c-4b3a-9627-845840eb5e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While writing code, we can speed things up by shortenning the time period.\n",
    "debugging = False\n",
    "if debugging:\n",
    "    price_df = price_df.group_by(\"region\").head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f19be1f-8f2a-4299-b919-8194b1117375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(region, is_diagonal, region_price_df):\n",
    "    print(f\"Computing result for {region} {is_diagonal=}\")\n",
    "    start_time = time()\n",
    "    # strange nested dicts:\n",
    "    # https://pyomo.readthedocs.io/en/stable/howto/abstract_models/data/raw_dicts.html#page-data-from-dict\n",
    "    instance = model.create_instance(\n",
    "        {\n",
    "            None: {\n",
    "                \"period\": {None: region_price_df[\"period\"]},\n",
    "                \"prices\": {\n",
    "                    t: p\n",
    "                    for (t, p) in zip(\n",
    "                        region_price_df[\"period\"], region_price_df[\"price\"]\n",
    "                    )\n",
    "                },\n",
    "                \"is_diagonal\": {None: is_diagonal},\n",
    "                \"h_per_interval\": {None: region_metadata[region][\"h_per_interval\"]},\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    result = SolverFactory(\"glpk\", executable=\"/usr/bin/glpsol\").solve(instance)\n",
    "\n",
    "    assert (\n",
    "        result[\"Solver\"][0][\"Termination condition\"] != \"infeasible\"\n",
    "    ), f\"infeasible for {region}\"\n",
    "\n",
    "    mid_time = time()\n",
    "\n",
    "    # s_per_min\n",
    "    print(\n",
    "        f\"Calculations for {region} {is_diagonal=} took {(mid_time - start_time) :.1f} s\"\n",
    "    )\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    # values indexed only on time\n",
    "    for col in [\"revenue\", \"power_net_avg\", \"power_net_end\", \"charge_end\"]:\n",
    "        data[col] = [getattr(instance, col)[t].value for t in instance.period]\n",
    "\n",
    "    # values indexed on time and direction\n",
    "    for col in [\"power_gross_avg\", \"power_gross_end\"]:\n",
    "        for d in instance.directions:\n",
    "            data[col] = [getattr(instance, col)[t, d].value for t in instance.period]\n",
    "\n",
    "    # for values indexed on time, and direction\n",
    "    for col in [\"power_gross_avg\"]:\n",
    "        for d in instance.directions:\n",
    "            data[col.replace(\"gross\", d)] = [\n",
    "                getattr(instance, col)[t, d].value for t in instance.period\n",
    "            ]\n",
    "\n",
    "    df = (\n",
    "        pl.DataFrame(data)\n",
    "        .with_row_index(name=\"period\")\n",
    "        .with_columns(\n",
    "            pl.lit(is_diagonal).alias(\"is_diagonal\"),\n",
    "        )\n",
    "        .join(region_price_df, how=\"left\", on=\"period\")\n",
    "    )\n",
    "\n",
    "\n",
    "    return df #(df, instance, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1159eedd-791e-4023-91b4-9c911410dabe",
   "metadata": {},
   "source": [
    "If you're using Windows, the next cell may fail. If so, this is a problem with your installation of python, not with my code. This is a known issue with Jupyter + multiprocessing + windows. Either get the code sample at the top of [this doc page](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing) working, or rewrite the cell below this one with a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa05385-8b5f-4ac9-88aa-8d675eeb0b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def echo(x):\n",
    "    return x\n",
    "\n",
    "payload = list(range(5))\n",
    "with Pool() as p:\n",
    "    result = p.map(echo, payload)\n",
    "\n",
    "assert result == payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c79dbc8-c504-479f-8644-c6bd71d8029b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tasks = []\n",
    "# for (region, ) in price_df.select(\"region\").unique().iter_rows():\n",
    "#     for is_diagonal in [True, False]:\n",
    "#         input_df = price_df.filter(pl.col(\"region\") == region)\n",
    "#         tasks.append((region, is_diagonal, input_df))\n",
    "\n",
    "\n",
    "# def _solve_unwrap(payload):\n",
    "#     (region, is_diagonal, input_df) = payload\n",
    "#     return solve(region, is_diagonal, input_df)\n",
    "\n",
    "\n",
    "# with Pool(processes=cpu_count() - 1) as p:\n",
    "#     results_iter = p.map(_solve_unwrap, tasks)\n",
    "# print('calculated, now concating')\n",
    "# results = pl.concat(results_iter, how=\"vertical_relaxed\")\n",
    "# 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ed0a5-d9f0-4b8d-9604-b68d3dedc564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# regions = [r for (r,) in price_df.select(\"region\").unique().iter_rows()]\n",
    "# regions\n",
    "\n",
    "# def _solve_unwrap(payload):\n",
    "#     (region, is_diagonal) = payload\n",
    "#     input_df = price_df.filter(pl.col(\"region\") == region)\n",
    "#     return solve(region, is_diagonal, input_df)\n",
    "\n",
    "\n",
    "\n",
    "# with Pool(processes=cpu_count() - 1) as p:\n",
    "#     results_iter = p.map(_solve_unwrap, product(regions, [True, False]))\n",
    "# results = pl.concat(results_iter, how=\"vertical_relaxed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c81b1f4-fef6-43a5-a866-0b32f9e6da71",
   "metadata": {},
   "source": [
    "Multiprocessing hangs on completion. I don't know why. I guess Polars' arrow backend can't handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7ac5f8-ce75-49ee-8331-71a1c478a9c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for (region,) in price_df.select(\"region\").unique().iter_rows():\n",
    "    for is_diagonal in [True, False]:\n",
    "        assert isinstance(region, str), f\"Bad iter_rows() call: {region}\"\n",
    "        #h_per_interval = region_metadata[region][\"h_per_interval\"]\n",
    "        input_df = price_df.filter(pl.col(\"region\") == region)\n",
    "        output_df = solve(region, is_diagonal, input_df)\n",
    "        results.append(output_df)\n",
    "results = pl.concat(results, how=\"vertical_relaxed\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfdeece-2048-491e-a8f4-ba5993859ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb56182-f174-4f67-9812-57259856a3b6",
   "metadata": {},
   "source": [
    "### Analyse Results\n",
    "\n",
    "#### Summary Stats\n",
    "\n",
    "Start with single statistics.\n",
    "\n",
    "For \"partial cycles\", we want to count how many times the battery changes direction from charge to discharge, or back. Counting partial cycles (not fully depleting/charging.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e5960-1099-43ab-9a73-acec5e050c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(results_location, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d6d58f-dcaf-4c4a-a21d-93f9eadc9887",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary = (\n",
    "    results.with_columns(\n",
    "        pl.when(pl.col(\"power_net_avg\") > 0)\n",
    "        .then(1)\n",
    "        .when(pl.col(\"power_net_avg\") < 0)\n",
    "        .then(-1)\n",
    "        .fill_null(strategy=\"forward\")\n",
    "        .alias(\"direction\")\n",
    "    )\n",
    "    .with_columns(\n",
    "        (pl.col(\"direction\").shift(1).over(\"region\") != pl.col(\"direction\")).alias(\n",
    "            \"change_direction\"\n",
    "        )\n",
    "    )\n",
    "    .join(region_metadata_df, on=\"region\")\n",
    "    .group_by(\"region\", \"is_diagonal\")\n",
    "    .agg(\n",
    "        (pl.col(\"power_charge_avg\") * pl.col(\"h_per_interval\"))\n",
    "        .sum()\n",
    "        .alias(\"total_charged_mwh\"),\n",
    "        (pl.col(\"power_discharge_avg\") * pl.col(\"h_per_interval\"))\n",
    "        .sum()\n",
    "        .alias(\"total_discharged_gwh\"),\n",
    "        pl.col(\"revenue\").sum().alias(\"total_revenue\"),\n",
    "        pl.col(\"change_direction\").sum().alias(\"direction_changes\"),\n",
    "    )\n",
    "    .sort(\"region\", \"is_diagonal\")\n",
    ")\n",
    "results_summary.write_csv(os.path.join(results_location, \"simulation-results.csv\"))\n",
    "\n",
    "results_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8329b5-8f4d-4052-9d6f-6bb04b3a9ad0",
   "metadata": {},
   "source": [
    "Now let's print the table into a form I can put into Typst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a964134-1cec-4cb8-b24e-811a67a0b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\n",
    "    (\"total_discharged_gwh\", \"Energy (GWh)\", 2, gw_per_mw),\n",
    "    (\"total_revenue\", \"Profit (\\\\$k)\", 1, 1 / 1000),\n",
    "    # (\"direction_changes\", \"Partial Cycles\", 0, 1),\n",
    "]\n",
    "\n",
    "num_columns = 1 + 1 + 3 * len(attributes)\n",
    "\n",
    "table_output = os.path.join(results_location, \"simulation-results.typ\")\n",
    "\n",
    "header = f\"\"\"\n",
    "#set text(size: 9.5pt)\n",
    "#table(\n",
    "    columns: {num_columns},\n",
    "    align: horizon,\n",
    "    stroke: (x: none, y: 0.4pt),\n",
    "    table.cell(\n",
    "        colspan: 2,\n",
    "    )[Region],\n",
    "\"\"\"\n",
    "\n",
    "with open(table_output, \"w\") as f:\n",
    "\n",
    "    f.write(header)\n",
    "\n",
    "    for i, (df_col, table_col, dp, scale) in enumerate(attributes):\n",
    "        f.write(f\"  table.cell(colspan: 3,)[{table_col}],\\n\")\n",
    "        # if i < len(attributes) - 1: # if not last\n",
    "        #    f.write(\"  [],\\n\")\n",
    "\n",
    "    f.write(\"  [Name], [Interval],\\n\")\n",
    "    for i, (df_col, table_col, dp, scale) in enumerate(attributes):\n",
    "        f.write(f\"  [#text(blue)[Step]], [#text(red)[Diagonal]], [Difference],\\n\")\n",
    "        # if i < len(attributes) - 1: # if not last\n",
    "        #    f.write(\"  [],\\n\")\n",
    "\n",
    "    regions = [r for (r,) in results.select(\"region\").unique().iter_rows()]\n",
    "    table_row = 3\n",
    "    for j, region in enumerate(regions):\n",
    "        if region.lower() != \"fake\":\n",
    "            interval_min = region_metadata[region][\"interval_min\"]\n",
    "            if interval_min == min_per_h:\n",
    "                interval_s = f\"1h\"\n",
    "            else:\n",
    "                interval_s = f\"{interval_min}m\"\n",
    "            f.write(f\"  [{region}], [{interval_s}],\\n\")\n",
    "            for i, (df_col, table_col, dp, scale) in enumerate(attributes):\n",
    "                stepped = (\n",
    "                    results_summary.filter(pl.col(\"region\") == region)\n",
    "                    .filter(pl.col(\"is_diagonal\").not_())\n",
    "                    .select(df_col)\n",
    "                    .item()\n",
    "                ) * scale\n",
    "                diagonal = (\n",
    "                    results_summary.filter(pl.col(\"region\") == region)\n",
    "                    .filter(pl.col(\"is_diagonal\"))\n",
    "                    .select(df_col)\n",
    "                    .item()\n",
    "                ) * scale\n",
    "                diff = (stepped - diagonal) / stepped\n",
    "                f.write(\n",
    "                    f\"     [{stepped:.{dp}f}], [{diagonal:.{dp}f}], [{diff * 100:.1f} %],\\n\"\n",
    "                )\n",
    "\n",
    "            if j < len(regions) - 1:  # if not last\n",
    "                f.write(f\"    table.hline(y: {table_row}, stroke: none),\\n\")\n",
    "            table_row += 1\n",
    "    f.write(\")\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec3db36-205c-49fe-b2ba-fb0c10d567f4",
   "metadata": {},
   "source": [
    "Now print it as a LaTeX table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f42025-d1e1-4052-83ea-4e9778aa18ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = 2 + 3 * len(attributes)\n",
    "\n",
    "table_output = os.path.join(results_location, \"simulation-results.tex\")\n",
    "\n",
    "col_spec = 'll' + 'r' * 3 * len(attributes)\n",
    "\n",
    "with open(table_output, \"w\") as f:\n",
    "\n",
    "    f.write(\"\\\\begin{tabular}{@{}\" + col_spec + \"@{}}\\n\")\n",
    "    f.write(\"  \\\\toprule\\n\")\n",
    "    f.write(\"  \\\\multicolumn{2}{c}{Region}\\n\")\n",
    "\n",
    "    for (df_col, table_col, dp, scale) in attributes:\n",
    "        f.write(\"    & \\\\multicolumn{3}{c}{\" + table_col + \"}\\n\")\n",
    "    f.write(\"    \\\\\\\\\")\n",
    "\n",
    "    f.write(\"    Name & Interval\\n\")\n",
    "    for (df_col, table_col, dp, scale) in attributes:\n",
    "        f.write(\"   & Stepped & Diagonal & Difference\\n\")\n",
    "    f.write(\"    \\\\\\\\ \\\\midrule\\n\")\n",
    "\n",
    "    regions = [r for (r,) in results.select(\"region\").unique().iter_rows()]\n",
    "    for region in regions:\n",
    "        if region.lower() != \"fake\":\n",
    "            interval_min = region_metadata[region][\"interval_min\"]\n",
    "            if interval_min == min_per_h:\n",
    "                interval_str = f\"1h\"\n",
    "            else:\n",
    "                interval_str = f\"{interval_min}m\"\n",
    "\n",
    "            f.write(f\"    {region} & {interval_str}\\n\")\n",
    "            \n",
    "            for df_col, table_col, dp, scale in attributes:\n",
    "                stepped = (\n",
    "                    results_summary.filter(pl.col(\"region\") == region)\n",
    "                    .filter(pl.col(\"is_diagonal\").not_())\n",
    "                    .select(df_col)\n",
    "                    .item()\n",
    "                ) * scale\n",
    "                diagonal = (\n",
    "                    results_summary.filter(pl.col(\"region\") == region)\n",
    "                    .filter(pl.col(\"is_diagonal\"))\n",
    "                    .select(df_col)\n",
    "                    .item()\n",
    "                ) * scale\n",
    "                diff = (stepped - diagonal) / stepped\n",
    "                f.write(\n",
    "                    f\"      & {stepped:,.{dp}f} & {diagonal:,.{dp}f} & {diff * 100:.1f} \\\\% \\n\"\n",
    "                )\n",
    "            f.write(\"    \\\\\\\\ \\n\")\n",
    "    f.write(\"  \\\\bottomrule\")\n",
    "    f.write(\"\\\\end{tabular}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f0a7f-cf35-4e19-8d82-70d18970c160",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5dad5d-4cc6-4234-97f3-becd2788e792",
   "metadata": {},
   "source": [
    "Now find the period of time where the results differ the most, and then plot a time-series window showing the difference. For each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f6bc8b-e20e-4cde-991d-a5982abb4eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 12\n",
    "interesting_periods = (\n",
    "    results.pivot(\"is_diagonal\", index=[\"period\", \"region\"], values=\"power_net_avg\")\n",
    "    .rename({\"true\": \"diagonal\", \"false\": \"step\"})\n",
    "    .with_columns((pl.col(\"step\") - pl.col(\"diagonal\")).pow(2).alias(\"difference\"))\n",
    "    .sort(\"period\")\n",
    "    .cast({\"period\": pl.Int32})\n",
    "    .group_by_dynamic(\"period\", every=f\"{window_size}i\", group_by=\"region\")\n",
    "    .agg(pl.col(\"difference\").sum())\n",
    "    .sort(\"difference\", descending=True)\n",
    "    .group_by(\"region\")\n",
    "    .head(1)\n",
    "    .select(\"region\", \"period\")\n",
    ")\n",
    "interesting_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71624d6-2d39-4dff-9ed3-bfd900be4cb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for region, period in interesting_periods.iter_rows():\n",
    "\n",
    "    fig = sp.make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
    "\n",
    "    plot_df = results.filter(pl.col(\"region\") == region).filter(\n",
    "        pl.col(\"period\").is_between(\n",
    "            period - (window_size // 2), period + 2 * window_size\n",
    "        )\n",
    "    )\n",
    "\n",
    "    diagonal_df = plot_df.filter(pl.col(\"is_diagonal\") == True)\n",
    "    step_df = plot_df.filter(pl.col(\"is_diagonal\") == False)\n",
    "    price_plot_df = diagonal_df  # choose either, to deduplicate\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=diagonal_df[\"period\"],\n",
    "            y=diagonal_df[\"power_net_end\"],\n",
    "            mode=\"lines\",\n",
    "            marker={\"color\": \"blue\"},\n",
    "            name=\"diagonal\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=step_df[\"period\"],\n",
    "            y=step_df[\"power_net_end\"],\n",
    "            mode=\"lines\",\n",
    "            line={\"color\": \"red\", \"shape\": \"vh\"},\n",
    "            name=\"stepped\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=price_plot_df[\"time\"],\n",
    "            y=price_plot_df[\"price\"],\n",
    "            mode=\"lines\",\n",
    "            line={\"shape\": \"vh\"},\n",
    "            name=\"Prices\",\n",
    "        ),\n",
    "        row=2,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "    #fig.update_layout(title=f\"Simulation Results - {region}\")\n",
    "    fig.update_yaxes(title_text=\"Power (MW)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Prices ($/MWh)\", row=2, col=1)\n",
    "\n",
    "    h_per_interval = region_metadata[region][\"h_per_interval\"]\n",
    "    ms_per_interval = h_per_interval * ms_per_h\n",
    "    fig.update_xaxes(\n",
    "        title_text=\"Time\", minor=dict(dtick=ms_per_interval, showgrid=True)\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    for ext in ['svg', 'pdf']:\n",
    "        fig.write_image(os.path.join(results_location, f\"plot-{region}.{ext}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251bc8eb-b7eb-4464-86e7-4fa8db01b23d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
